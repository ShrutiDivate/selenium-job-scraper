from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
import pandas as pd
import time

print("ğŸš€ Step 1: Setting up Chrome browser (visible mode)...")

options = Options()
options.add_argument("--start-maximized")   # opens browser full screen
# NOTE: No headless mode here â€” browser will be visible

driver = webdriver.Chrome(
    service=Service(ChromeDriverManager().install()), 
    options=options
)

print("âœ… Chrome launched successfully!")

# ----------------------------------------------------
print("\nğŸš€ Step 2: Opening the job listing website...")
url = "https://realpython.github.io/fake-jobs/"
driver.get(url)

time.sleep(2)
print("âœ… Website opened successfully!")

# ----------------------------------------------------
print("\nğŸš€ Step 3: Waiting for page content to load...")
time.sleep(2)
print("â³ Job cards loading...")

# ----------------------------------------------------
print("\nğŸš€ Step 4: Extracting job details...")

titles = driver.find_elements(By.CLASS_NAME, "title.is-5")
companies = driver.find_elements(By.CLASS_NAME, "subtitle.is-6.company")
locations = driver.find_elements(By.CLASS_NAME, "location")
links = driver.find_elements(By.XPATH, "//a[text()='Apply']")

print(f"ğŸ“Œ Found {len(titles)} jobs!")

# ----------------------------------------------------
print("\nğŸš€ Step 5: Reading each job entry...")

data = []
for i in range(len(titles)):
    print(f"   â¤ Extracting job {i+1}/{len(titles)}...")

    data.append({
        "title": titles[i].text,
        "company": companies[i].text,
        "location": locations[i].text,
        "apply_link": links[i].get_attribute("href")
    })
    time.sleep(0.2)

# ----------------------------------------------------
print("\nğŸš€ Step 6: Saving data to CSV...")

df = pd.DataFrame(data)
df.to_csv("selenium_job_scrape.csv", index=False)

print("ğŸ“„ CSV saved as selenium_job_scrape.csv")

# ----------------------------------------------------
print("\nğŸš€ Step 7: Closing the browser...")
time.sleep(2)
driver.quit()
print("âŒ Browser closed!")

# ----------------------------------------------------
print("\nğŸ‰ Scraping complete! Check your selenium_job_scrape.csv file.")
